{"meta":{"title":"Omer Wu bar","subtitle":"","description":"This is a open source software collection website","author":"Omer","url":"http://example.com","root":"/"},"pages":[{"title":"tags","date":"2024-04-03T08:13:51.000Z","updated":"2024-04-03T08:18:17.059Z","comments":false,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"about","date":"2024-04-03T08:13:57.000Z","updated":"2024-04-03T08:18:40.410Z","comments":false,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":""},{"title":"categories","date":"2024-04-03T08:13:37.000Z","updated":"2024-04-03T08:18:02.963Z","comments":false,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"resources","date":"2024-04-03T08:14:04.000Z","updated":"2024-04-03T08:18:52.229Z","comments":false,"path":"resources/index.html","permalink":"http://example.com/resources/index.html","excerpt":"","text":""}],"posts":[{"title":"iTransformer:时间序列预测的最新突破","slug":"itransformer_gpt","date":"2024-04-11T15:55:10.000Z","updated":"2024-04-11T10:43:08.614Z","comments":true,"path":"2024/04/11/itransformer_gpt/","permalink":"http://example.com/2024/04/11/itransformer_gpt/","excerpt":"在本文中，我们发现 iTransformer 背后极其简单的概念并探索其架构。然后，我们将该模型应用到一个小型实验中，并将其性能与TSMixer、N-HiTS和 PatchTST 进行比较。","text":"预测领域在基础模型领域开展了大量活动，自 2024 年初以来就提出了Lag-LLaMA、Time-LLM、Chronos和 Moirai 等模型。 然而，它们的性能有点令人印象深刻（对于可重复的基准，请参见此处），并且我相信特定于数据的模型仍然是目前的最佳解决方案。 为此，Transformer 架构已以多种形式应用于时间序列预测，其中PatchTST实现了长期预测的最先进性能。 具有挑战性的 PatchTST 是iTransformer模型，该模型于 2024 年 3 月在论文iTransformer：Inverted Transformers Are effective for Time Series Forecasting中提出。 在本文中，我们发现 iTransformer 背后极其简单的概念并探索其架构。然后，我们将该模型应用到一个小型实验中，并将其性能与TSMixer、N-HiTS和 PatchTST 进行比较。 欲了解更多详细信息，请务必阅读原始论文。 让我们开始吧！ 探索 iTransformeriTransformer 背后的想法来自于对普通 Transformer 模型使用时间_标记_的认识。 这意味着该模型会在单个时间步长中查看所有特征。因此，模型在一次查看一个时间步骤时学习时间依赖性是一项挑战。 该问题的解决方案是修补，这是通过 PatchTST 模型提出的。通过修补，我们只需将时间点分组在一起，然后再对其进行标记和嵌入，如下所示。 可视化修补。在这里，我们有一个包含 15 个时间步长的序列，补丁长度为 5，步幅也为 5，从而产生三个补丁。图片由作者提供。 在 iTransformer 中，我们通过简单地将模型应用到反转维度上，将修补推向了极致。 iTransformer应用在系列的倒立形状上。这样，跨时间的整个功能就被标记化和嵌入了。图片由 Y. Liu、T. Hu、H. Zhang、H. Wu、S. Wang、L. Ma、M. Long 提供，来自iTransformer：反向变压器对于时间序列预测非常有效。 在上图中，我们可以看到 iTransformer 与普通 Transformer 的不同之处。它不是在一个时间步长中查看所有特征，而是在多个时间步长中查看一个特征。这只需通过反转输入的形状即可完成。 这样，注意力层可以学习多元相关性，前馈网络对整个输入序列的表示进行编码。 现在我们已经掌握了 iTransformer 背后的总体思路，让我们更详细地了解一下它的架构。 iTransformer的架构iTransformer 采用带有嵌入、投影和 Transformer 块的普通编码器-解码器架构，最初是在 2017 年的开创性论文《Attention Is All You Need》中提出的。 iTransformer 的架构。图片由 Y. Liu、T. Hu、H. Zhang、H. Wu、S. Wang、L. Ma、M. Long 提供，来自iTransformer：反向变压器对于时间序列预测非常有效。 从上图中我们可以看出，构建块是相同的，但功能却完全不同。让我们仔细看看。 嵌入层 首先，输入序列作为标记独立嵌入。同样，这就像修补的极端情况，模型不是对输入的子序列进行标记，而是对整个输入序列进行标记。 多变量注意力 然后，嵌入被发送到注意力层，在那里它将学习多元相关图。 这是可能的，因为倒置模型将每个特征视为一个独立的过程。因此，注意力机制可以学习特征对之间的相关性，使 iTransformer 特别适合多元预测任务。 层归一化 注意力层的输出被发送到归一化层。 在传统的 Transformer 架构中，所有特征都在固定的时间戳上完成归一化。这可能会引入交互噪声，这意味着模型正在学习无用的关系。另外，它可能会导致信号过于平滑。 相比之下，由于 iTransformer 反转了维度，因此标准化是跨时间戳完成的。这有助于模型处理非平稳序列，并减少序列中的噪声。 前馈网络 最后，前馈网络（FFN）学习传入令牌的深度表示。 同样，由于形状是倒置的，多层感知器 (MLP) 可以学习不同的时间属性，例如周期性和幅度。这模仿了基于 MLP 的模型的功能，例如N-BEATS、N-HiTS 和 TSMixer。 投影 从这里开始，只需堆叠许多由以下组成的块即可： 注意力层 层归一化 前馈网络 层归一化 每个块学习输入序列的不同表示。然后，通过线性投影步骤发送块堆栈的输出以获得最终预测。 综上所述，iTransformer 并不是一个新的架构；它并没有重新发明变压器。它只是将其应用于输入的反转维度，这使得模型能够学习多元相关性并捕获时间属性。 现在我们对 iTransformer 模型有了深入的了解，让我们将其应用到一个小型的预测实验中。 使用 iTransformer 进行预测对于这个小实验，我们在 Creative Commons 许可下发布的Electricity Transformer 数据集上应用了 iTransformer 模型。 这是一个流行的基准数据集，用于跟踪中国一个省两个地区的电力变压器的油温。对于这两个区域，我们每小时和每 15 分钟采样一个数据集，总共四个数据集。 虽然 iTransformer 本质上是一个多变量模型，但我们在 96 个时间步长的范围内测试其单变量预测能力。 此实验的代码可在GitHub上找到。 让我们开始吧！ 初始设置 _在这个实验中，我们使用了Neuralforecast_库，因为我相信它提供了深度学习方法最快、最直观的即用型实现。 123456import pandas as pd import numpy as np import matplotlib.pyplot as plt from datasetsforecast.long_horizon import LongHorizon from neuralforecast.core import NeuralForecast from neuralforecast.models import NHITS, PatchTST, iTransformer, TSMixer 请注意，在撰写本文时，iTransformer 尚未在Neuralforecast_的_公开版本中提供。要立即访问模型，您可以运行： pip install git+https://github.com/Nixtla/neuralforecast.git 现在，让我们编写一个函数来加载 ETT 数据集及其验证大小、测试大小和频率。 1234567891011121314151617181920212223242526272829def load_data(name): if name == &quot;ettm1&quot;: Y_df, *_ = LongHorizon.load(directory=&#x27;./&#x27;, group=&#x27;ETTm1&#x27;) Y_df = Y_df[Y_df[&#x27;unique_id&#x27;] == &#x27;OT&#x27;] Y_df[&#x27;ds&#x27;] = pd.to_datetime(Y_df[&#x27;ds&#x27;]) val_size = 11520 test_size = 11520 freq = &#x27;15T&#x27; elif name == &quot;ettm2&quot;: Y_df, *_ = LongHorizon.load(directory=&#x27;./&#x27;, group=&#x27;ETTm2&#x27;) Y_df = Y_df[Y_df[&#x27;unique_id&#x27;] == &#x27;OT&#x27;] Y_df[&#x27;ds&#x27;] = pd.to_datetime(Y_df[&#x27;ds&#x27;]) val_size = 11520 test_size = 11520 freq = &#x27;15T&#x27; elif name == &#x27;etth1&#x27;: Y_df, *_ = LongHorizon.load(directory=&#x27;./&#x27;, group=&#x27;ETTh1&#x27;) Y_df[&#x27;ds&#x27;] = pd.to_datetime(Y_df[&#x27;ds&#x27;]) val_size = 2880 test_size = 2880 freq = &#x27;H&#x27; elif name == &quot;etth2&quot;: Y_df, *_ = LongHorizon.load(directory=&#x27;./&#x27;, group=&#x27;ETTh2&#x27;) Y_df[&#x27;ds&#x27;] = pd.to_datetime(Y_df[&#x27;ds&#x27;]) val_size = 2880 test_size = 2880 freq = &#x27;H&#x27; return Y_df, val_size, test_size, freq _上面的函数可以方便地以Neuroforecast_期望的格式加载数据，其中我们有一个unique_id用于标记唯一时间序列的列，一个ds用于时间戳的列，以及一个y包含我们的序列值的列。 另请注意，验证和测试规模与科学界在发表论文时使用的一致。 我们现在准备好训练模型了。 训练和预测要训​​练 iTransformer 模型，我们只需指定： 预测范围 输入尺寸 系列数 请记住，iTransformer 本质上是一个多元模型，这就是为什么我们在拟合模型时需要指定系列数。 由于我们处于单变量场景，n_series&#x3D;1. 12345iTransformer(h=horizon, input_size=3*horizon, n_series=1, max_steps=1000, early_stop_patience_steps=3) 在上面的代码块中，我们还指定了最大训练步骤数，并将提前停止设置为三次迭代以避免过度拟合。 然后我们对其他模型执行相同的操作，并将它们放入列表中。 12345678horizon = 96models = [ iTransformer(h=horizon, input_size=3*horizon, n_series=1, max_steps=1000, early_stop_patience_steps=3), TSMixer(h=horizon, input_size=3*horizon, n_series=1, max_steps=1000, early_stop_patience_steps=3), NHITS(h=horizon, input_size=3*horizon, max_steps=1000, early_stop_patience_steps=3), PatchTST(h=horizon, input_size=3*horizon, max_steps=1000, early_stop_patience_steps=3)] 伟大的！现在，我们只需初始化该NeuralForecast对象即可访问训练、交叉验证和预测的方法。 12nf = NeuralForecast(models=models, freq=freq)nf_preds = nf.cross_validation(df=Y_df, val_size=val_size, test_size=test_size, n_windows=None) 最后，我们使用该库评估每个模型的性能utilsforecast。 12345from utilsforecast.losses import mae, msefrom utilsforecast.evaluation import evaluateettm1_evaluation = evaluate(df=nf_preds, metrics=[mae, mse], models=[&#x27;iTransformer&#x27;, &#x27;TSMixer&#x27;, &#x27;NHITS&#x27;, &#x27;PatchTST&#x27;])ettm1_evaluation.to_csv(&#x27;ettm1_results.csv&#x27;, index=False, header=True) 然后对所有数据集重复这些步骤。运行该实验的完整函数如下所示。 123456789101112131415161718192021222324from utilsforecast.losses import mae, msefrom utilsforecast.evaluation import evaluatedatasets = [&#x27;ettm1&#x27;, &#x27;ettm2&#x27;, &#x27;etth1&#x27;, &#x27;etth2&#x27;]for dataset in datasets: Y_df, val_size, test_size, freq = load_data(dataset) horizon = 96 models = [ iTransformer(h=horizon, input_size=3*horizon, n_series=1, max_steps=1000, early_stop_patience_steps=3), TSMixer(h=horizon, input_size=3*horizon, n_series=1, max_steps=1000, early_stop_patience_steps=3), NHITS(h=horizon, input_size=3*horizon, max_steps=1000, early_stop_patience_steps=3), PatchTST(h=horizon, input_size=3*horizon, max_steps=1000, early_stop_patience_steps=3) ] nf = NeuralForecast(models=models, freq=freq) nf_preds = nf.cross_validation(df=Y_df, val_size=val_size, test_size=test_size, n_windows=None) nf_preds = nf_preds.reset_index() evaluation = evaluate(df=nf_preds, metrics=[mae, mse], models=[&#x27;iTransformer&#x27;, &#x27;TSMixer&#x27;, &#x27;NHITS&#x27;, &#x27;PatchTST&#x27;]) evaluation.to_csv(f&#x27;&#123;dataset&#125;_results.csv&#x27;, index=False, header=True) 一旦运行完成，我们就可以从所有数据集上的所有模型中获得预测。然后我们可以继续进行评估。 绩效评估_由于我们将所有性能指标保存在 CSV 文件中，因此我们可以使用pandas_读取它们并绘制每个数据集的每个模型的性能。 12345678910111213files = [&#x27;etth1_results.csv&#x27;, &#x27;etth2_results.csv&#x27;, &#x27;ettm1_results.csv&#x27;, &#x27;ettm2_results.csv&#x27;]datasets = [&#x27;etth1&#x27;, &#x27;etth2&#x27;, &#x27;ettm1&#x27;, &#x27;ettm2&#x27;]dataframes = []for file, dataset in zip(files, datasets): df = pd.read_csv(file) df[&#x27;dataset&#x27;] = dataset dataframes.append(df)full_df = pd.concat(dataframes, ignore_index=True)full_df = full_df.drop([&#x27;unique_id&#x27;], axis=1) 然后，绘制指标： 12345678910111213141516171819202122232425262728293031323334353637import matplotlib.pyplot as pltimport numpy as npdataset_names = full_df[&#x27;dataset&#x27;].unique()model_names = [&#x27;iTransformer&#x27;, &#x27;TSMixer&#x27;, &#x27;NHITS&#x27;, &#x27;PatchTST&#x27;]fig, axs = plt.subplots(2, 2, figsize=(15, 15)) bar_width = 0.35 axs = axs.flatten()for i, dataset_name in enumerate(dataset_names): df_subset = full_df[(full_df[&#x27;dataset&#x27;] == dataset_name) &amp; (full_df[&#x27;metric&#x27;] == &#x27;mae&#x27;)] mae_vals = df_subset[model_names].values.flatten() df_subset = full_df[(full_df[&#x27;dataset&#x27;] == dataset_name) &amp; (full_df[&#x27;metric&#x27;] == &#x27;mse&#x27;)] mse_vals = df_subset[model_names].values.flatten() indices = np.arange(len(model_names)) bars_mae = axs[i].bar(indices - bar_width / 2, mae_vals, bar_width, color=&#x27;skyblue&#x27;, label=&#x27;MAE&#x27;) bars_mse = axs[i].bar(indices + bar_width / 2, mse_vals, bar_width, color=&#x27;orange&#x27;, label=&#x27;MSE&#x27;) for bars in [bars_mae, bars_mse]: for bar in bars: height = bar.get_height() axs[i].annotate(f&#x27;&#123;height:.2f&#125;&#x27;, xy=(bar.get_x() + bar.get_width() / 2, height), xytext=(0, 3), textcoords=&quot;offset points&quot;, ha=&#x27;center&#x27;, va=&#x27;bottom&#x27;) axs[i].set_xticks(indices) axs[i].set_xticklabels(model_names, rotation=45) axs[i].set_title(dataset_name) axs[i].legend(loc=&#x27;best&#x27;)plt.tight_layout() 来自 ETT 数据集上所有模型的 MAE 和 MSE，范围为 96 个时间步长。图片由作者提供。 从上图可以看出，iTransformer 在所有数据集上的表现都相当不错，但 TSMixer 整体略好于 iTransformer，PatchTST 是本次实验中整体冠军模型。 当然，请记住，我们没有利用 iTransformer 的多变量功能，并且我们仅在单个预测范围内进行测试。因此，它并不是对 iTransformer 性能的完整评估。 尽管如此，有趣的是看到该模型的表现与 PatchTST 非常接近，这进一步支持了这样的想法：在使用 Transformer 进行时间序列预测时，在标记化之前将时间步分组在一起可以解锁新的性能高度。 结论iTransformer 采用普通 Transformer 架构，并将其简单地应用于输入序列的反转形状。 这样，整个系列就被标记化了，这模仿了 PatchTST 中提出的修补的极端情况。 这使得模型能够使用其注意力机制来学习多元相关性，而前馈网络则学习序列的时间属性。 尽管在我们有限的实验中，PatchTST 的整体表现最好，但 iTransformer 在许多基准数据集上的长期预测中表现出了最先进的性能。 我坚信每个问题都需要其独特的解决方案，现在您可以将 iTransformer 添加到您的工具箱并将其应用到您的项目中。 谢谢阅读！我希望您喜欢它并学到新东西！","categories":[],"tags":[]},{"title":"用 Python 创建赢率 百分之74 的倒卖策略","slug":"python_win_rate","date":"2024-04-08T15:55:10.000Z","updated":"2024-04-11T10:11:42.500Z","comments":true,"path":"2024/04/08/python_win_rate/","permalink":"http://example.com/2024/04/08/python_win_rate/","excerpt":"在本文中，我将解释我使用 Python 实现的策略以及如何开发该策略。因此，我们将首先了解有关交易策略的一些背景知识，然后继续进行编码部分","text":"介绍最近，我暂时停止了对使用技术指标构建的常规交易策略的回测，并继续疯狂搜索以探索一些非常规策略。就在那时，我了解到了倒卖交易的概念以及市场上交易者如何使用它。 我对此很着迷，并尝试了该策略。我想出了自己的倒卖策略，并在 Python 中对其进行了回溯测试，结果非常有趣。 在本文中，我将解释我使用 Python 实现的策略以及如何开发该策略。因此，我们将首先了解有关交易策略的一些背景知识，然后继续进行编码部分，在该部分中，我们将使用FinancialModelingPrep (FMP) API数据，并在 Python 中回测我们的策略。 话不多说，让我们一起进入本文吧！ 我们的倒卖交易策略在深入研究我们的交易策略机制之前，有必要首先对倒卖交易的概念有一些了解。 倒卖交易倒卖交易是一种非常规的交易方式，交易者旨在从微小的价格波动中获利。 例如，遵循倒卖交易的交易者会以 170 美元的价格买入大量苹果 (AAPL) 股票，并计划以非常小的价格涨幅（如 170.5 美元或 171 美元）出售该股票。 以较小的价格变化快速抛售股票的原因是每笔交易涉及大量资金。剥头皮交易只有在资金雄厚的情况下才能获得可观的利润。 交易策略现在我们已经很好地了解了什么是剥头皮交易，让我们深入研究我们的交易策略。 因此，剥头皮交易的基本思想是从微小的价格变化中获利。显然，我们不能使用它作为我们的策略，因为它太生硬了，但我们可以做的就是将其作为我们交易策略的基础，并且我们需要在此基础上创建有效的剥头皮策略。 以下是我们交易策略的机制： 如果出现以下情况，我们入市：市场开盘价较前一日收盘价上涨 1%。 我们在以下情况退出市场：股票价格较买入价（即当日开盘价）上涨 1%。如果股票价格未能达到 1% 的涨幅，我们将在交易日结束时以收盘价退出。 这里的目标不是创建一个具有各种进入和退出条件的复杂策略，而是创建一个简单的策略来理解剥头皮交易的本质。话虽如此，让我们继续编码部分！ 导入包第一步也是最重要的一步是将所有必需的包导入到我们的 Python 环境中。在本文中，我们将使用四个包，它们是： Pandas — 用于数据格式化、清除、操作和其他相关目的 Matplotlib — 用于创建图表和不同类型的可视化 request — 用于进行 API 调用以提取数据 Termcolor — 自定义 Jupyter Notebook 中显示的标准输出 math— 用于各种数学函数和运算 NumPy — 用于数值和高级数学函数 以下代码将上述所有包导入到我们的Python环境中： 1234567# IMPORTING PACKAGES import requests import pandas as pd import matplotlib.pyplot as plt from termcolor import colored as cl import numpy as np import math 如果您尚未安装任何导入的软件包，请确保使用pip终端中的命令来安装。 提取历史数据获取股票的历史数据对于回测过程非常重要。为了数据的准确性和可靠性，我们将使用**FinancialModelingPrep (FMP) 的历史数据端点**，该端点允许提取任何特定股票的日终数据。我们将对 Tesla 股票的倒卖策略进行回测，以下代码提取 2014 年初以来的历史数据： 1234567891011# EXTRACTING HISTORICAL DATAapi_key = &#x27;YOUR API KEY&#x27;tsla_json = requests.get(f&#x27;https://financialmodelingprep.com/api/v3/historical-price-full/TSLA?from=2014-01-01&amp;apikey=&#123;api_key&#125;&#x27;).json()tsla_df = pd.DataFrame(tsla_json[&#x27;historical&#x27;]).drop(&#x27;label&#x27;, axis = 1)tsla_df = tsla_df.set_index(&#x27;date&#x27;)tsla_df = tsla_df.iloc[::-1]tsla_df.index = pd.to_datetime(tsla_df.index)tsla_df 代码非常简单。我们首先将 API 密钥存储在api_key变量中。确保替换为您[创建 FMP 开发人员帐户] YOUR API KEY后可以获得的秘密 API 密钥。 然后，使用getRequests包提供的函数，我们调用API来获取TSLA的历史数据。最后，我们将提取的 JSON 响应转换为可用的 Pandas 数据帧以及一些数据操作，这是输出： 使用 FMP 的 API 提取的 TSLA 历史数据（作者图片） 我真正喜欢 FMP 历史数据端点提供的 API 响应的一件事是它附带的大量附加数据。除了 OHLC 数据之外，您还可以获得 VWAP、变化百分比等，这些数据在某些情况下非常有用。 计算变化百分比并过滤根据交易策略，如果当日开盘价比前一日收盘价高1%，我们就进场。为此，我们首先需要借助获得的历史数据来计算价格变化的百分比。以下代码执行相同的操作： 12345678910111213# CALCULATING % CHANGEtsla_df[&#x27;pclose_open_pc&#x27;] = np.nanfor i in range(1, len(tsla_df)): diff, avg = (tsla_df.close[i-1] - tsla_df.open[i]) , (tsla_df.close[i-1] + tsla_df.open[i])/2 pct_change = (diff / avg)*100 tsla_df[&#x27;pclose_open_pc&#x27;][i] = pct_change tsla_df = tsla_df.dropna().drop([&#x27;change&#x27;, &#x27;changePercent&#x27;, &#x27;changeOverTime&#x27;], axis = 1)tsla_df = tsla_df[tsla_df.pclose_open_pc &gt; 1]tsla_df 代码可能看起来有点模糊，包含所有的 for 循环和其他内容，但实际上非常简单。让我来分解一下。 首先，我们创建一个名为pclose_open_pc存储百分比变化值的新列。然后是 for 循环。这个 for 循环背后的主要思想是复制pct_change()Pandas 提供的函数的功能。 我们在 for 循环的帮助下所做的唯一改变是计算两个不同变量之间的百分比变化。即，当天的开盘价和前一天的收盘价是不可能的，但pct_change()允许计算单个变量的当前值和旧值之间的百分比变化。 之后，我们删除一些列，并使用一个条件对数据帧进行切片，该条件选择百分比变化大于 1 的行，即当天的开盘价比前一天的收盘价高 1%。 这是所有处理后的最终数据帧： 过滤后的 TSLA 历史数据（作者提供的图片） 现在我们已经准备好了数据，是时候实际构建和测试我们的剥头皮交易策略了。 回测策略我们已经完成了本文中最重要和最有趣的步骤之一。现在我们已经了解了交易策略的细节，让我们用 Python 构建它并进行回测。为了简单起见，我们将遵循一个非常基本且简单的回测系统。以下代码回测了倒卖策略： 123456789101112131415161718192021222324252627282930313233343536373839404142434445investment = 100000equity = investmentearning = 0earnings_record = []for i in range(len(tsla_df)): # EXTRACTING INTRADAY DATA date = str(tsla_df.index[i])[:10] intra_json = requests.get(f&#x27;https://financialmodelingprep.com/api/v3/historical-chart/1min/TSLA?from=&#123;date&#125;&amp;to=&#123;date&#125;&amp;apikey=&#123;api_key&#125;&#x27;).json() intra_df = pd.DataFrame(intra_json) intra_df = intra_df.set_index(pd.to_datetime(intra_df.date)).iloc[::-1] # ENTERING POSITION open_p = tsla_df.iloc[i].open no_of_shares = math.floor(equity/open_p) equity -= (no_of_shares * open_p) # EXITING POSITION intra_df[&#x27;p_change&#x27;] = np.nan for i in range(len(intra_df)): diff, avg = (intra_df.close[i] - open_p), (intra_df.close[i] + open_p)/2 pct_change = (diff / avg)*100 intra_df[&#x27;p_change&#x27;][i] = pct_change intra_df = intra_df.dropna() greater_1 = intra_df[intra_df.p_change &gt; 1] if len(greater_1) &gt; 0: sell_price = greater_1.iloc[0].close equity += (no_of_shares * sell_price) else: sell_price = intra_df.iloc[-1].close equity += (no_of_shares * sell_price) # CALCULATING TRADE EARNINGS investment += earning earning = round(equity-investment, 2) earnings_record.append(earning) if earning &gt; 0: print(cl(&#x27;PROFIT:&#x27;, color = &#x27;green&#x27;, attrs = [&#x27;bold&#x27;]), f&#x27;Earning on &#123;date&#125;: $&#123;earning&#125;; Bought &#x27;, cl(f&#x27;&#123;no_of_shares&#125;&#x27;, attrs = [&#x27;bold&#x27;]), &#x27;stocks at &#x27;, cl(f&#x27;$&#123;open_p&#125;&#x27;, attrs = [&#x27;bold&#x27;]), &#x27;and Sold at &#x27;, cl(f&#x27;$&#123;sell_price&#125;&#x27;, attrs = [&#x27;bold&#x27;])) else: print(cl(&#x27;LOSS:&#x27;, color = &#x27;red&#x27;, attrs = [&#x27;bold&#x27;]), f&#x27;Loss on &#123;date&#125;: $&#123;earning&#125;; Bought &#x27;, cl(f&#x27;&#123;no_of_shares&#125;&#x27;, attrs = [&#x27;bold&#x27;]), &#x27;stocks at &#x27;, cl(f&#x27;$&#123;open_p&#125;&#x27;, attrs = [&#x27;bold&#x27;]), &#x27;and Sold at &#x27;, cl(f&#x27;$&#123;sell_price&#125;&#x27;, attrs = [&#x27;bold&#x27;])) 我不会深入研究每一行代码，而是尝试给出这个回测系统代码的要点。 基本上，代码可以分为四个部分（如代码注释中所示）： 第一个是使用FMP 的日内数据端点提取我们进入市场时的日内数据。 第二部分是我们通过以当天开盘价买入股票来建仓的地方。 第三部分是退出仓位的代码，我们首先计算价格变化的百分比，然后一旦价格上涨 1%，我们就平仓。 第四部分专门计算每笔交易的收益并将结果打印在输出终端中。 该程序进行了大量交易，虽然无法显示其中一笔交易，但以下是已执行交易的一瞥： 程序生成的交易（作者提供的图片） 输出包括所有必要的详细信息，例如股票数量、买入价、卖出价、日期和收益。虽然有一些亏损的交易，但大多数都是盈利的交易，收益合理。 策略回报分析与评估在本节中，我们将深入探讨该策略的绩效。让我们从策略回报和投资回报率的基本指标开始。以下代码计算策略的总收益和投资回报率： 123456789# STRATEGY RETURNSprint(cl(f&#x27;TSLA BACKTESTING RESULTS:&#x27;, attrs = [&#x27;bold&#x27;]))print(&#x27; &#x27;)strategy_earning = round(equity - 100000, 2)roi = round(strategy_earning / 100000 * 100, 2)print(cl(f&#x27;EARNING: $&#123;strategy_earning&#125; ; ROI: &#123;roi&#125;%&#x27;, attrs = [&#x27;bold&#x27;])) 代码非常简单。我们只是应用数学公式来计算总收益和投资回报率 (ROI)，以得出最终数字，这是最终输出： 回测结果（作者图片） 因此，我们的剥头皮交易策略在十年（2014-2024）期间创造了 11 万美元的总收入，投资回报率为 110%。那还不错。虽然结果不是压倒性的，但仍然相当不错。 现在让我们使用一些基本指标来评估我们的交易策略。但为了计算这些指标，我们首先创建并处理数据： 12345earnings_df = pd.DataFrame(columns = [&#x27;date&#x27;, &#x27;earning&#x27;])earnings_df.date = tsla_df.indexearnings_df.earning = earnings_recordearnings_df.tail() 此代码的主要目的是创建一个数据框，其中包含该策略在每个交易日产生的收益的详细信息。借助earnings_record我们在回测代码中创建的用于记录收益数据的列表，我们可以轻松地从中创建一个 Pandas 数据框，而这正是我们在代码中所做的。这是最终的输出： 盈利数据（作者图片） 现在我们已经有了所需的数据，我们现在可以继续计算评估我们的交易策略所需的指标。在此之前，这是我们将用于评估的指标列表： 最大损失：最差交易的收益 最大利润：最佳交易的收益 交易总数：策略生成的交易总和 胜率：策略成功的概率 每月平均交易量和每月平均收益 以下代码计算所有上述讨论的指标： 123456789101112131415161718192021222324252627max_loss = earnings_df.earning.min()max_profit = earnings_df.earning.max()no_of_wins = len(earnings_df.iloc[np.where(earnings_df.earning &gt; 0)[0]])no_of_losses = len(earnings_df.iloc[np.where(earnings_df.earning &lt; 0)[0]])no_of_trades = no_of_wins+no_of_losseswin_rate = (no_of_wins/(no_of_wins + no_of_losses))*100print(cl(&#x27;MAX LOSS:&#x27;, color = &#x27;red&#x27;, attrs = [&#x27;bold&#x27;]), f&#x27;$&#123;max_loss&#125;;&#x27;, cl(&#x27;MAX PROFIT:&#x27;, color = &#x27;green&#x27;, attrs = [&#x27;bold&#x27;]), f&#x27;&#123;max_profit&#125;;&#x27;, cl(&#x27;TOTAL TRADES:&#x27;, attrs = [&#x27;bold&#x27;]), f&#x27;&#123;no_of_trades&#125;;&#x27;, cl(&#x27;WIN RATE:&#x27;, attrs = [&#x27;bold&#x27;]), f&#x27;&#123;round(win_rate)&#125;%;&#x27;, cl(&#x27;AVG. TRADES/MONTH:&#x27;, attrs = [&#x27;bold&#x27;]), f&#x27;&#123;round(no_of_trades/120)&#125;;&#x27;, cl(&#x27;AVG. EARNING/MONTH:&#x27;, attrs = [&#x27;bold&#x27;]), f&#x27;$&#123;round(strategy_earning/120)&#125;&#x27; )plt.style.use(&#x27;ggplot&#x27;)earnings_df.earning.hist()plt.title(&#x27;Earnings Distribution&#x27;)plt.show()earnings_df = earnings_df.set_index(&#x27;date&#x27;)earnings_df.earning.cumsum().plot()plt.title(&#x27;Strategy Cumulative Returns&#x27;)plt.show() 除了计算指标之外，代码中还涉及一些可视化，我们将在稍后讨论。这是输出： 策略绩效（作者提供的图片） 我们首先谈谈指标。最大损失为 $15.1k，最大利润为 $5K。问题是，最大损失的绝对值小于最大利润总是更好，因为它可以降低策略的风险。 十年间该策略产生的交易总数为 501 笔。这个数字并不压倒性，这是一件好事。一个月平均执行的交易数量为 4 笔，这也是一个合理的交易数量。每月平均回报为 923 美元，这是一个可靠的数字。 最重要的指标是胜率。我们的策略胜率是74%。这意味着我们的策略有 74% 的机会执行盈利交易，这是令人难以置信的。胜率大于 50% 的策略被认为是有效且风险较小的。但如果没有适当的风险管理系统，这个数字仍然没有任何意义。 就图表而言，在上面的输出中可以看到其中两个。第一个是直方图，显示我们策略的收益分布。可以看出，大部分交易的收益在 1500-2500 美元左右。 第二张图是折线图，显示了我们交易策略的累积收益。首先可以注意到的是线路的不稳定运动。这表明该策略的收益波动很大，这意味着我们的策略在某些情况下是不稳定且有风险的。最好避免图表中所示的突然下跌。 买入&#x2F;持有回报比较一个好的交易策略不仅应该能够产生有利可图的回报，而且必须足够有效以优于买入&#x2F;持有策略。对于那些不知道什么是买入&#x2F;持有策略的人来说，这是一种交易者无论情况如何都长期买入并持有股票的策略。 如果我们的策略击败了买入&#x2F;持有策略，我们可以自信地说，我们想出了一个很好的交易策略，几乎可以在现实世界中部署。然而，如果做不到这一点，我们就必须对策略做出相当大的改变。 以下代码实现买入&#x2F;持有策略并计算收益： 12345678910api_key = &#x27;YOUR API KEY&#x27;json = requests.get(f&#x27;https://financialmodelingprep.com/api/v3/historical-price-full/TSLA?from=2014-01-01&amp;apikey=&#123;api_key&#125;&#x27;).json()df = pd.DataFrame(json[&#x27;historical&#x27;]).drop(&#x27;label&#x27;, axis = 1)df = df.set_index(&#x27;date&#x27;)df = df.iloc[::-1]df.index = pd.to_datetime(df.index)tsla_roi = round(list(df[&#x27;close&#x27;].pct_change().cumsum())[-1],4)*100print(cl(f&#x27;BUY/HOLD STRATEGY ROI: &#123;round(tsla_roi,2)&#125;%&#x27;, attrs = [&#x27;bold&#x27;])) 在上面的代码中，我们再次使用FMP 的历史数据端点提取 Tesla 的历史数据，因为我们对之前提取的数据进行了一些更改。经过一些数据操作后，我们使用简单的数学来计算回报，这是最终的输出： 买入&#x2F;持有策略投资回报率（作者图片） 在比较买入&#x2F;持有策略和我们的剥头皮交易策略的结果后，买入&#x2F;持有策略的投资回报率相差 333%，优于我们的策略。这是什么意思？这意味着在将其推向市场之前，我们必须在剥头皮策略上做很多工作。 结论尽管我们经历了制定交易策略、使用历史和日内数据以及对策略进行回测的广泛过程，但我们仍然未能超越买入&#x2F;持有策略。但本文的目的不是展示借助这些策略的任何赚钱方法，而是对剥头皮交易进行温和的介绍。 如果您确实想将这一策略转变为高利润策略并将其部署到市场，您可以进行一些改进来实现这一目标。首先是调整策略参数。尝试调整进入和退出条件，并测试哪一个最适合交易策略。接下来是建立适当的风险管理体系。这是我们在本文中没有讨论的内容，但它非常重要，尤其是当您想将该策略应用于现实市场时。 话虽如此，您已经到达了本文的结尾。希望您今天学到了一些新的有用的东西。如果您有任何改进交易策略的建议，请在评论中告诉我。非常感谢您的宝贵时间","categories":[],"tags":[]},{"title":"Python 中的蒙特卡洛模拟：高级投资风险分析","slug":"Monte_Carlo_Simulation","date":"2024-04-07T14:55:10.000Z","updated":"2024-04-11T10:11:47.125Z","comments":true,"path":"2024/04/07/Monte_Carlo_Simulation/","permalink":"http://example.com/2024/04/07/Monte_Carlo_Simulation/","excerpt":"蒙特卡罗模拟是一种利用重复随机采样来获得数值结果的计算算法。该方法的基本原理是利用随机性来解决原则上可能是确定性的问题。它以摩纳哥蒙特卡洛赌场命名，因为该方法固有的机会元素，类似于赌博。这种方法在包括金融和贸易在内的许多领域特别有用，可用于对涉及不确定性的场景进行建模并预测风险的影响。","text":"什么是蒙特卡罗模拟？蒙特卡罗模拟是一种利用重复随机采样来获得数值结果的计算算法。该方法的基本原理是利用随机性来解决原则上可能是确定性的问题。它以摩纳哥蒙特卡洛赌场命名，因为该方法固有的机会元素，类似于赌博。这种方法在包括金融和贸易在内的许多领域特别有用，可用于对涉及不确定性的场景进行建模并预测风险的影响。 我对它在金融中的应用特别感兴趣。在股票和加密货币市场的背景下，蒙特卡罗模拟用于通过模拟资产价格的各种可能结果来预测未来的价格变动。鉴于金融市场的随机性，这种方法非常适合评估投资固有的风险和不确定性。投资者和分析师使用它来模拟不同盈利潜力的概率，帮助他们通过了解可能结果的范围以及实现不同回报水平的可能性来做出明智的决策。 股票和加密货币的蒙特卡罗模拟对于股票和加密货币，模拟通常涉及根据历史波动性和价格趋势预测未来价格。该过程通常涉及以下内容： 历史数据分析: 分析历史价格数据（例如开盘价、最高价、最低价、收盘价（OHLC）数据）以确定平均收益和波动性。 随机样本生成: 根据历史平均回报和波动率，使用统计模型生成随机每日回报。 价格模拟: 通过将随机生成的收益应用到当前价格来重复计算未来的价格路径。 结果分析: 评估模拟未来价格的分布，以估计不同结果的概率。 用 Python 演示蒙特卡洛模拟我想分两部分向您展示它是如何工作的，这样更容易理解。 Part 1第一步是检索一些历史交易数据以供使用。我订阅了EODHD APIs，这就是我检索数据进行分析的地方。他们还有一个名为“ eodhd ”的 Python 库，使检索数据成为一项微不足道的任务。在本演示中，我将检索 S&amp;P 500 每日股票数据。 python3 -m pip install eodhd -U 12345678import numpy as np import matplotlib.pyplot as plt from eodhd import APIClient API_KEY = &quot;&amp;lt;YOUR_KEY&amp;gt;&quot; api = APIClient(API_KEY) df = api.get_historical_data(&quot;GSPC.INDX&quot;, &quot;d&quot;, results=365) print(df) 123# Calculate daily returnsdaily_returns = df[&quot;adjusted_close&quot;].pct_change().dropna()print(daily_returns) 1234567891011121314# Simulation parametersnum_simulations = 1000forecast_days = 365# Initialise simulation array, all zerossimulations = np.zeros((num_simulations, forecast_days))# Simulate future pathslast_price = df[&quot;adjusted_close&quot;].iloc[-1]for i in range(num_simulations): cumulative_returns = np.random.choice(daily_returns, size=forecast_days, replace=True).cumsum() simulations[i, :] = last_price * (1 + cumulative_returns)print(simulations) 绘制结果… 1234567#Plotting the results plt.figure(figsize=(10, 6)) plt.plot(simulations.T, color=&quot;blue&quot;, alpha=0.025) plt.title(&quot;Monte Carlo Simulation of Future Prices&quot;) plt.xlabel(&quot;Day&quot;) plt.ylabel(&quot;Price&quot;) plt.show() 这看起来不错，但它真正向我们展示了什么？ 波动性表示: 模拟根据历史波动性捕获可能的价格变动范围，提供不确定性的直观表示。然而，它假设过去的波动模式将继续下去，但情况可能并非总是如此。 预测局限性: 虽然模拟有助于理解潜在结果，但无法预测具体的未来价格。市场状况、经济因素和不可预见的事件都会极大地影响实际结果。 情景规划: 模拟结果的分布可以帮助投资者规划各种情景，评估收益潜力和损失风险。它鼓励对未来市场走势采取概率性而非确定性的观点。 模型假设: 模拟的准确性在很大程度上取决于对回报分布和波动性的假设。不同的模型（例如，假设正态回报与对数正态回报）可能会产生不同的结果，这凸显了模型选择和校准的重要性。 Part 2在第 1 部分中，我想向您介绍基础知识。我不指望你能用它做任何有用的事情。这就是我现在要向您展示的内容。 蒙特卡罗模拟在评估投资风险和制定投资决策方面的实际应用涉及几个关键步骤。通过了解第 1 部分中所示的模拟生成的潜在未来价格的范围和分布，投资者可以量化投资的风险和潜在回报。下面是它的实际应用方式： 1. 明确投资目标和风险承受能力投资者或投资组合经理首先要确定他们的投资目标，包括预期回报和他们愿意承受的风险水平。风险承受能力可能受到投资期限、财务目标以及投资者个人对不确定性的接受程度等因素的影响。 2. 运行蒙特卡罗模拟使用历史数据和统计模型，进行大量模拟来预测所考虑的投资（股票、加密货币等）的未来价格路径。每个模拟都代表了基于每日收益随机发生的未来可能的场景，反映了历史波动性和收益模式。希望第 1 部分已经清楚这一点。 3. 分析仿真输出蒙特卡罗模拟的输出提供了未来指定时间的一系列可能的未来价格。然后分析该范围以了解投资的潜在结果。模拟得出的关键指标包括： 概率分布: 投资者将查看模拟最终价格的分布，以了解结果的分布。例如，价差较大表明波动性较高，因此风险较高。. 风险价值 (VaR): 该指标估计给定置信水平下指定时间范围内的最大潜在损失。例如，95% VaR 为 1,000 英镑意味着投资者在指定期间内损失不会超过 1,000 英镑的可能性为 95%。 预期尾部损失 (ETL): 也称为条件 VaR，ETL 提供超出 VaR 阈值的平均损失，从而深入了解最坏情况下的潜在损失。 4. 做出明智的决定根据分析，投资者可以通过将蒙特卡罗模拟揭示的风险和回报状况与其投资目标和风险承受能力进行比较，做出明智的决策。例如： 如果实现预期回报的概率超过投资者的成功门槛，并且相关风险（VaR、ETL）在其风险承受范围内，则该投资可能被认为是可接受的。 如果模拟显示回报达不到目标或风险超出投资者的承受能力的可能性很大，他们可能会决定调整投资策略。这可能涉及投资组合多元化、选择具有不同风险回报状况的投资或改变投资期限。 实际例子:我想考虑在标准普尔 500 指数中投资 10,000 英镑，并且我想使用蒙特卡罗模拟来评估风险。模拟应表明，在 95% 的置信度下，投资明年的损失不会超过 2,000 英镑 (95% VaR)。此外，模拟应表明有 50% 的机会实现至少 10% 的回报。 举个例子，我的风险承受能力允许潜在的 2,000 英镑损失，而目标是 10% 的回报，这项投资可能被认为在可接受的风险参数范围内。然而，如果潜在损失超出投资者的风险承受能力，或者认为实现预期回报的可能性太低，投资者可能会寻找替代方案或修改投资金额。 该过程说明了蒙特卡罗模拟在投资风险评估和决策中的实际应用。它提供了一种结构化的方法来考虑上行潜力和下行风险，支持与特定风险回报目标相一致的更细致的投资策略。 这在 Python 中会是什么样子？首先，我想对我的模拟参数进行一些调整。 1234567891011121314151617# Calculate daily returnsdaily_returns = df[&quot;adjusted_close&quot;].pct_change().dropna()# Simulation parametersinitial_investment = 10000 # Initial investment amountnum_simulations = 1000 # Number of simulationsforecast_days = 365 # Investment horizon in daysdesired_return = 0.10 # Desired return (10%)# Calculate the average daily returnaverage_daily_return = daily_returns.mean()# Calculate volatility as the standard deviation of daily returnsvolatility = daily_returns.std()print(f&quot;Average Daily Return: &#123;average_daily_return&#125;&quot;)print(f&quot;Volatility: &#123;volatility&#125;&quot;) 只是为了兴趣，如果您更喜欢对数正态回报，您可以这样做…… 1daily_returns = np.log(df[&quot;adjusted_close&quot;] / df[&quot;adjusted_close&quot;].shift(1)).dropna() 我改进了模拟逻辑…… 1234567891011# Simulating future returnssimulated_end_returns = np.zeros(num_simulations)for i in range(num_simulations): random_returns = np.random.normal(average_daily_return, volatility, forecast_days) cumulative_return = np.prod(1 + random_returns) simulated_end_returns[i] = initial_investment * cumulative_return# Calculate the final investment valuesfinal_investment_values = simulated_end_returnsprint(final_investment_values) 此屏幕截图仅显示“final_investment_values”数组的一个子集，让您了解它的外观。 计算风险价值 (VaR) 和预期尾部损失（条件 VaR）12345678confidence_level = 0.95sorted_returns = np.sort(final_investment_values)index_at_var = int((1-confidence_level) * num_simulations)var = initial_investment - sorted_returns[index_at_var]conditional_var = initial_investment - sorted_returns[:index_at_var].mean()print(f&quot;Value at Risk (95% confidence): £&#123;var:,.2f&#125;&quot;)print(f&quot;Expected Tail Loss (Conditional VaR): £&#123;conditional_var:,.2f&#125;&quot;) 这告诉我什么?风险价值 (VaR) 和预期尾部损失（条件 VaR）是用于了解投资损失潜力的衡量标准，但它们的理解方式略有不同。 风险价值 (VaR)当我们说“风险价值（95% 置信度）：-1,926.81 英镑”时，这意味着根据过去的表现和当前条件，您的投资在指定时间段内损失不会超过 1,926.81 英镑的可能性为 95% 。简单来说，这就像说：“我们非常确定（95% 确定）在大多数情况下，您会做的最糟糕的事情就是损失 1,926.81 英镑。” 预期尾部损失（条件 VaR）另一方面，“预期尾部损失（条件 VaR）：-1,301.08 英镑”着眼于那些超出我们刚才谈到的 95% 置信水平的非常糟糕的日子。它问的是，“如果事情确实比我们预期的更糟，而我们又处于那不幸的 5% 中，那么我们预计情况平均会变得多糟？”这个数字告诉我们，平均而言，在最坏的情况下，您可能会损失约 1,301.08 英镑。 把它放在一起这两个指标都为您提供了一种以熟悉的货币术语来思考风险的方法，这非常有帮助。 VaR 为您提供了一个阈值，表示“情况不太可能变得比这更糟”，而预期尾部损失告诉您，“但如果情况确实变得更糟，这就是您可能期望的情况。” 这就像在计划一次野餐时说：“有 95% 的可能性，下雨不会超过小毛毛雨，但如果我们真的不走运，下起了倾盆大雨，我们预计会是中雨，而不是倾盆大雨。 ”它不仅可以帮助您为可能的结果做好准备，还可以帮助您了解并计划最坏的情况，即使它们发生的可能性较小。 让我们继续……1234num_success = np.sum(final_investment_values &gt;= initial_investment * (1 + desired_return))probability_of_success = num_success / num_simulationsprint(f&quot;Probability of achieving at least a &#123;desired_return*100&#125;% return: &#123;probability_of_success*100:.2f&#125;%&quot;) 我还对 matplotlib 图形代码进行了调整以显示直方图。 12345678910111213plt.figure(figsize=(10, 6))plt.hist(final_investment_values, bins=50, alpha=0.75)plt.axvline( initial_investment * (1 + desired_return), color=&quot;r&quot;, linestyle=&quot;dashed&quot;, linewidth=2,)plt.axvline(initial_investment - var, color=&quot;g&quot;, linestyle=&quot;dashed&quot;, linewidth=2)plt.title(&quot;Distribution of Final Investment Values&quot;)plt.xlabel(&quot;Final Investment Value&quot;)plt.ylabel(&quot;Frequency&quot;)plt.show() 了解上面红色和绿色虚线的含义很重要。 红虚线 目的：该线表示与期望回报相对应的投资价值。 计算： 计算为initial_investment * (1 + desired_return)。本质上，如果您从一定数量的资金 ( ) 开始，这条线显示了如果您的投资按照您期望的回报 ( )initial_investment的百分比增长，您最终会达到什么水平。desired_return 解释：红线回答了这个问题：“我希望我的投资至少最终会在哪里？”它代表了我的投资目标。查看直方图时，该线右侧的任何结果（或直方图中的条形）都意味着我已经达到或超过了我的预期回报。相反，左侧的结果表明未达到我的目标。 绿色虚线 目的：此线标记指定置信水平（在本例中为 95%）的风险价值 (VaR)。 计算：如图所示initial_investment - var。var这里代表我在 95% 的置信度下损失的英镑金额，这意味着我的损失只有 5% 的机会超过这个金额。 解释：绿线为风险评估提供了视觉提示。它告诉我，“考虑到我所意识到的风险，这是我在相当高的信心下可能损失的金额。”在直方图的背景下，它让我了解我的投资的潜在结果中有多少涉及损失超过我相对满意的范围。如果许多结果落在这条线的左边，我的投资可能比我愿意接受的风险更大。 查看直方图时： 红线右侧的区域表示我的投资的最终价值达到或超过我的目标回报的成功结果。绿线左侧的区域突出显示了损失在 95% 的情况下超过我预期的结果部分，表明结果有比预期更糟糕的风险。这些线共同有助于直观地体现模拟结果中利润潜力（红线）和损失风险（绿线）之间的平衡。 希望您发现这很有用…如果您希望我的代码在不同的市场上试用，这里是…… 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081import numpy as npimport matplotlib.pyplot as pltfrom eodhd import APIClientimport config as cfgapi = APIClient(cfg.API_KEY)def get_ohlc_data(): df = api.get_historical_data(&quot;GSPC.INDX&quot;, &quot;d&quot;, results=365) return dfif __name__ == &quot;__main__&quot;: df = get_ohlc_data() # Calculate daily returns daily_returns = df[&quot;adjusted_close&quot;].pct_change().dropna() # Simulation parameters initial_investment = 10000 # Initial investment amount num_simulations = 1000 # Number of simulations forecast_days = 365 # Investment horizon in days desired_return = 0.10 # Desired return (10%) # Calculate the average daily return average_daily_return = daily_returns.mean() # Calculate volatility as the standard deviation of daily returns volatility = daily_returns.std() print(f&quot;Average Daily Return: &#123;average_daily_return&#125;&quot;) print(f&quot;Volatility: &#123;volatility&#125;&quot;) # Simulating future returns simulated_end_returns = np.zeros(num_simulations) for i in range(num_simulations): random_returns = np.random.normal( average_daily_return, volatility, forecast_days ) cumulative_return = np.prod(1 + random_returns) simulated_end_returns[i] = initial_investment * cumulative_return # Calculate the final investment values final_investment_values = simulated_end_returns # Calculate Value at Risk (VaR) and Expected Tail Loss (Conditional VaR) confidence_level = 0.95 sorted_returns = np.sort(final_investment_values) index_at_var = int((1 - confidence_level) * num_simulations) var = initial_investment - sorted_returns[index_at_var] conditional_var = initial_investment - sorted_returns[:index_at_var].mean() print(f&quot;Value at Risk (95% confidence): £&#123;var:,.2f&#125;&quot;) print(f&quot;Expected Tail Loss (Conditional VaR): £&#123;conditional_var:,.2f&#125;&quot;) num_success = np.sum( final_investment_values &gt;= initial_investment * (1 + desired_return) ) probability_of_success = num_success / num_simulations print( f&quot;Probability of achieving at least a &#123;desired_return*100&#125;% return: &#123;probability_of_success*100:.2f&#125;%&quot; ) plt.figure(figsize=(10, 6)) plt.hist(final_investment_values, bins=50, alpha=0.75) plt.axvline( initial_investment * (1 + desired_return), color=&quot;r&quot;, linestyle=&quot;dashed&quot;, linewidth=2, ) plt.axvline(initial_investment - var, color=&quot;g&quot;, linestyle=&quot;dashed&quot;, linewidth=2) plt.title(&quot;Distribution of Final Investment Values&quot;) plt.xlabel(&quot;Final Investment Value&quot;) plt.ylabel(&quot;Frequency&quot;) plt.show()&quot;&quot;&quot;","categories":[],"tags":[]},{"title":"欢迎来到我的博客","slug":"hello-world","date":"2024-04-03T03:36:43.351Z","updated":"2024-04-11T10:07:51.857Z","comments":true,"path":"2024/04/03/hello-world/","permalink":"http://example.com/2024/04/03/hello-world/","excerpt":"","text":"欢迎来到Program bar，这是您获取最新科技新闻、富有洞察力的编码教程和突破性研究论文的首选中心。深入探索创新与教育相结合的世界，在这里我们揭开编码的复杂性，探索前沿技术，剖析最具影响力的研究成果。加入我们，踏上知识繁荣、激发好奇心、未来展现在您眼前的旅程","categories":[],"tags":[]}],"categories":[],"tags":[]}